{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of Bert.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6W1aW9ScsEKd","executionInfo":{"status":"ok","timestamp":1648844418695,"user_tz":240,"elapsed":18452,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}},"outputId":"dcf4c02b-2089-47de-8343-e9be4b84139b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import sys\n","\n","# TODO: change this to the path to your homework folder\n","# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'NLP /Final project/ChineseHumorSentiment-master/data'\n","# GOOGLE_DRIVE_PATH = os.path.join('drive', 'Shared drives', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","# print(os.listdir(GOOGLE_DRIVE_PATH))\n","# sys.path.append(GOOGLE_DRIVE_PATH)"],"metadata":{"id":"IGcW4IjHsQ7E","executionInfo":{"status":"ok","timestamp":1648844418776,"user_tz":240,"elapsed":85,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"uB4JJk4msXVG","executionInfo":{"status":"ok","timestamp":1648844419686,"user_tz":240,"elapsed":913,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["train_set = pd.read_csv(\"drive/Shared drives/NLP Final Project/Dataset/balanced_train_task1.csv\",encoding='utf8')\n","test_set = pd.read_csv(\"drive/Shared drives/NLP Final Project/Dataset/balanced_test_task1.csv\",encoding='utf8')\n","train_set = train_set.drop(columns=['id', 'Unnamed: 0'])\n","\n","\n","test_set = test_set.drop(columns=['id', 'Unnamed: 0'])"],"metadata":{"id":"X518fmy5sZFr","executionInfo":{"status":"ok","timestamp":1648844986394,"user_tz":240,"elapsed":234,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["import torch\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBYfHTEusbg-","executionInfo":{"status":"ok","timestamp":1648844987599,"user_tz":240,"elapsed":104,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}},"outputId":"ee5663ce-798f-45cf-c0d4-e67ee20f3e53"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["## Preprocessing"],"metadata":{"id":"s9SbTv08snyf"}},{"cell_type":"code","source":["! pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYJTXUsFsmp1","executionInfo":{"status":"ok","timestamp":1648844437123,"user_tz":240,"elapsed":10059,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}},"outputId":"bef78fc1-0788-4f3b-dbf9-50b904713d2b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 5.3 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 42.6 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 42.2 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.1 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Collecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 35.0 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}]},{"cell_type":"code","source":["train_set"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"rTHE_qHRtpLi","executionInfo":{"status":"ok","timestamp":1648844437219,"user_tz":240,"elapsed":109,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}},"outputId":"ac3297cb-e575-4e66-a65d-95ba14829e0d"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   joke  label\n","0                            当他们全都被困在一起时，他们为什么称他们为“公寓”？      0\n","1                                       总有一个白痴比你指望的还要多。      0\n","2                                    我们的父母和祖父母是一个更大的威胁！      0\n","3                       通过用细条培根覆盖任何切口和放牧，可以对猪进行轻微的皮肤移植。      0\n","4                                      有时我们不会想你。和它一起生活。      0\n","...                                                 ...    ...\n","7995                                四个食物组：快速，冷冻，速溶和巧克力。      0\n","7996                               不要把我与事实混淆，我的思绪已经弥补了！      1\n","7997  财务科长对一雇员说：“你太太请求我们把你的月薪支票直接寄给她。” “为什么？” “她说取消中...      1\n","7998                          如果橘子闻起来像鸡肉，为什么西红柿会变蓝？想一想！      0\n","7999            老公端起碗来狼吞虎咽，我：汤好喝吗？ 答：嗯，好喝，好喝，西红柿鸡蛋汤真好喝！      1\n","\n","[8000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-f80d6815-01d5-4538-917b-21c8a03a36cf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>joke</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>当他们全都被困在一起时，他们为什么称他们为“公寓”？</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>总有一个白痴比你指望的还要多。</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>我们的父母和祖父母是一个更大的威胁！</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>通过用细条培根覆盖任何切口和放牧，可以对猪进行轻微的皮肤移植。</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>有时我们不会想你。和它一起生活。</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7995</th>\n","      <td>四个食物组：快速，冷冻，速溶和巧克力。</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7996</th>\n","      <td>不要把我与事实混淆，我的思绪已经弥补了！</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7997</th>\n","      <td>财务科长对一雇员说：“你太太请求我们把你的月薪支票直接寄给她。” “为什么？” “她说取消中...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7998</th>\n","      <td>如果橘子闻起来像鸡肉，为什么西红柿会变蓝？想一想！</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7999</th>\n","      <td>老公端起碗来狼吞虎咽，我：汤好喝吗？ 答：嗯，好喝，好喝，西红柿鸡蛋汤真好喝！</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8000 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f80d6815-01d5-4538-917b-21c8a03a36cf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f80d6815-01d5-4538-917b-21c8a03a36cf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f80d6815-01d5-4538-917b-21c8a03a36cf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n","\n","example_text = train_set.iloc[400, 0]\n","bert_input = tokenizer(example_text,padding='max_length', max_length = 40, \n","                       truncation=True, return_tensors=\"pt\")"],"metadata":{"id":"fh4m2nT6sgvq","executionInfo":{"status":"ok","timestamp":1648844990658,"user_tz":240,"elapsed":869,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["print(bert_input['input_ids'])\n","print(bert_input['token_type_ids'])\n","print(bert_input['attention_mask'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-JS-2Ekqs7Vw","executionInfo":{"status":"ok","timestamp":1648844513183,"user_tz":240,"elapsed":98,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}},"outputId":"70d4689f-11d7-4a87-bfcb-f74e519fb1e1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 101, 2111, 2094, 4638, 4495, 3833, 2218, 1008,  671, 2476, 5291, 8024,\n","         3680,  702,  782, 6963, 4522,  678,  749, 1313, 6381,  511,  102,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0]])\n","tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"]}]},{"cell_type":"code","source":["example_text = tokenizer.decode(bert_input.input_ids[0])\n","\n","print(example_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_a1vmoO6tIcZ","executionInfo":{"status":"ok","timestamp":1648844518815,"user_tz":240,"elapsed":3117,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}},"outputId":"cb0d8f94-41ea-4e39-ee0a-f7c286dab96c"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] 孩 子 的 生 活 就 像 一 张 纸 ， 每 个 人 都 留 下 了 印 记 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n","labels = {'true': 1,\n","          'false': 0\n","          }\n","\n","class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df):\n","\n","        self.labels = [label for label in df['label']]\n","        self.texts = [tokenizer(text, \n","                               padding='max_length', max_length = 40, truncation=True,\n","                                return_tensors=\"pt\") for text in df['joke']]\n","\n","    def classes(self):\n","        return self.labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def get_batch_labels(self, idx):\n","        # Fetch a batch of labels\n","        return np.array(self.labels[idx])\n","\n","    def get_batch_texts(self, idx):\n","        # Fetch a batch of inputs\n","        return self.texts[idx]\n","\n","    def __getitem__(self, idx):\n","\n","        batch_texts = self.get_batch_texts(idx)\n","        batch_y = self.get_batch_labels(idx)\n","\n","        return batch_texts, batch_y"],"metadata":{"id":"2wSN-WNStZYY","executionInfo":{"status":"ok","timestamp":1648844993248,"user_tz":240,"elapsed":1046,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["from torch import nn\n","from transformers import BertModel\n","\n","class BertClassifier(nn.Module):\n","\n","    def __init__(self, dropout=0.5):\n","\n","        super(BertClassifier, self).__init__()\n","\n","        self.bert = BertModel.from_pretrained('bert-base-chinese')\n","        self.dropout = nn.Dropout(0.5)\n","        self.rnn = nn.LSTM(768, 200, num_layers = 3, device='cuda', batch_first=False, bidirectional=True, dropout=0.5)\n","        self.linear = nn.Linear(400, 2)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input_id, mask):\n","\n","        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n","        dropout_output = self.dropout(pooled_output)\n","        rnn_output, _ = self.rnn(dropout_output.view(len(dropout_output), 1, -1))\n","        dropout_output = self.dropout(rnn_output)\n","        linear_output = self.linear(dropout_output)\n","        dropout_output = self.dropout(linear_output)\n","        final_layer = (dropout_output).reshape((2, 2))\n","        return final_layer"],"metadata":{"id":"s8See-kHuVAz","executionInfo":{"status":"ok","timestamp":1648845782763,"user_tz":240,"elapsed":257,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["from torch.optim import Adam\n","from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","def train(model, train_data, val_data, learning_rate, epochs):\n","\n","    train, val = Dataset(train_data), Dataset(val_data)\n","\n","    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n","    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = Adam(model.parameters(), lr= learning_rate, weight_decay=1e-5)\n","\n","    if use_cuda:\n","\n","            model = model.cuda()\n","            criterion = criterion.cuda()\n","\n","    for epoch_num in range(epochs):\n","\n","            total_acc_train = 0\n","            total_loss_train = 0\n","\n","            for train_input, train_label in tqdm(train_dataloader):\n","\n","                train_label = train_label.to(device)\n","                mask = train_input['attention_mask'].to(device)\n","                input_id = train_input['input_ids'].squeeze(1).to(device)\n","\n","                output = model(input_id, mask)\n","                \n","                batch_loss = criterion(output, train_label)\n","                total_loss_train += batch_loss.item()\n","                acc = (output.argmax(dim=1) == train_label).sum().item()\n","                total_acc_train += acc\n","\n","                model.zero_grad()\n","                batch_loss.backward()\n","                optimizer.step()\n","            \n","            total_acc_val = 0\n","            total_loss_val = 0\n","\n","            with torch.no_grad():\n","\n","                for val_input, val_label in val_dataloader:\n","\n","                    val_label = val_label.to(device)\n","                    mask = val_input['attention_mask'].to(device)\n","                    input_id = val_input['input_ids'].squeeze(1).to(device)\n","\n","                    output = model(input_id, mask)\n","\n","                    batch_loss = criterion(output, val_label)\n","                    total_loss_val += batch_loss.item()\n","                    \n","                    acc = (output.argmax(dim=1) == val_label).sum().item()\n","                    total_acc_val += acc\n","\n","            print(\n","                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n","                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n","                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n","                | Val Accuracy: {total_acc_val / len(val_data): .3f} \\\n","                | Val Macro F1: {f1_score(output.argmax(dim=1).cpu().detach().numpy(), val_label.cpu().detach().numpy(), average=\"macro\")}')\n","                  \n","EPOCHS = 10\n","model = BertClassifier()\n","LR = 1e-6\n","              \n","train(model, train_set, test_set, LR, EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":677},"id":"KtFacpczu_75","outputId":"aff26885-88a7-4167-986c-1bd3e5b166cf","executionInfo":{"status":"error","timestamp":1648849496020,"user_tz":240,"elapsed":3712065,"user":{"displayName":"Vijay Sharma","userId":"16187083127470063947"}}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 4000/4000 [09:46<00:00,  6.82it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.346                 | Train Accuracy:  0.517                 | Val Loss:  0.343                 | Val Accuracy:  0.574                 | Val Macro F1: 1.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4000/4000 [09:44<00:00,  6.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.338                 | Train Accuracy:  0.614                 | Val Loss:  0.331                 | Val Accuracy:  0.683                 | Val Macro F1: 0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4000/4000 [09:49<00:00,  6.79it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.324                 | Train Accuracy:  0.702                 | Val Loss:  0.317                 | Val Accuracy:  0.714                 | Val Macro F1: 0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4000/4000 [09:49<00:00,  6.78it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.308                 | Train Accuracy:  0.724                 | Val Loss:  0.301                 | Val Accuracy:  0.728                 | Val Macro F1: 0.3333333333333333\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4000/4000 [09:43<00:00,  6.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.292                 | Train Accuracy:  0.721                 | Val Loss:  0.291                 | Val Accuracy:  0.719                 | Val Macro F1: 1.0\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4000/4000 [09:43<00:00,  6.85it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 6 | Train Loss:  0.278                 | Train Accuracy:  0.732                 | Val Loss:  0.278                 | Val Accuracy:  0.723                 | Val Macro F1: 1.0\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▉         | 358/4000 [00:52<08:51,  6.86it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-cbec1a6325d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0mLR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-6\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-29-cbec1a6325d9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[1;32m     40\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mbatch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mtotal_acc_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m                    \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                    \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'weight_decay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m                    eps=group['eps'])\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mexp_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate_steps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["torch.save(model,\"drive/Shared drives/NLP Final Project/Lawrence model/lstm+bert\")"],"metadata":{"id":"oVH_JxwzvelN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"pRcBXlkkq9Zb"},"execution_count":null,"outputs":[]}]}