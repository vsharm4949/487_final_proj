{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Human_label_accuracy.ipynb","provenance":[],"collapsed_sections":["s9SbTv08snyf"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"d058ac43cc0e4f568acfab6d6840ec73":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6d766a297f14c22b4bd11478abc4f73","IPY_MODEL_f5c407298af24c37a3bfe8c013e7fd00","IPY_MODEL_04740890d1a74a0aa4a08618abdfcbb0"],"layout":"IPY_MODEL_730f3da0565645deab733a07d2586734"}},"d6d766a297f14c22b4bd11478abc4f73":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_64d51e29603443d8a8c022729b0e8999","placeholder":"​","style":"IPY_MODEL_7cf385ddf184432d8753b3ece9cbb377","value":"Downloading: 100%"}},"f5c407298af24c37a3bfe8c013e7fd00":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb36be46ca4c4f979676a2719b8b1071","max":109540,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d92e7177e96c489eb77e5bf3ea0679fb","value":109540}},"04740890d1a74a0aa4a08618abdfcbb0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_46a9b80bf1ab4c3a92606088b3fdd090","placeholder":"​","style":"IPY_MODEL_e10cdbba720440bda681cc237b5008cb","value":" 107k/107k [00:00&lt;00:00, 682kB/s]"}},"730f3da0565645deab733a07d2586734":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64d51e29603443d8a8c022729b0e8999":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7cf385ddf184432d8753b3ece9cbb377":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb36be46ca4c4f979676a2719b8b1071":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d92e7177e96c489eb77e5bf3ea0679fb":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"46a9b80bf1ab4c3a92606088b3fdd090":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e10cdbba720440bda681cc237b5008cb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a22b8906f194753a7c727a6bddc62aa":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_06d3d0b51cdc4501b84dff909fbd2e97","IPY_MODEL_a275f10b895a4ebaad36df1d194d337e","IPY_MODEL_a9696fe46f3642a5af8e760cb49b9ce7"],"layout":"IPY_MODEL_3a9188b4afc84427bbd1a821e403ad2c"}},"06d3d0b51cdc4501b84dff909fbd2e97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6f3916ac59b42e78236004ea60ca999","placeholder":"​","style":"IPY_MODEL_cd549a4e49cd47f39baadd50aeee76b1","value":"Downloading: 100%"}},"a275f10b895a4ebaad36df1d194d337e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34b96e7e7f67440987b9dfc8d9a013fc","max":29,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c5cec62e3a494d2cbc61b5d7ac10ceea","value":29}},"a9696fe46f3642a5af8e760cb49b9ce7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e50fea7844e746c683bcb76391c668f4","placeholder":"​","style":"IPY_MODEL_c43288e4cf364c89bf5391e62f149ca6","value":" 29.0/29.0 [00:00&lt;00:00, 643B/s]"}},"3a9188b4afc84427bbd1a821e403ad2c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6f3916ac59b42e78236004ea60ca999":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd549a4e49cd47f39baadd50aeee76b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34b96e7e7f67440987b9dfc8d9a013fc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c5cec62e3a494d2cbc61b5d7ac10ceea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e50fea7844e746c683bcb76391c668f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c43288e4cf364c89bf5391e62f149ca6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d2a03c2a83a94d499c08123809d010ae":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b874273c33d24ad589214edf0e88f5a3","IPY_MODEL_381c42b53ba84b87949157fb706f30c1","IPY_MODEL_a712ecb04b8549b8a7128053db6a1187"],"layout":"IPY_MODEL_b951503897da4285a9f4ffdf3171a7f9"}},"b874273c33d24ad589214edf0e88f5a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_97697dc1702344528767d200bb154355","placeholder":"​","style":"IPY_MODEL_b853cc8dfb134c14b101fd357ef88c5d","value":"Downloading: 100%"}},"381c42b53ba84b87949157fb706f30c1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e7d36c5a9a442dd90deb45127106fc3","max":624,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b0df16a743174f559e1c872565109191","value":624}},"a712ecb04b8549b8a7128053db6a1187":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3fadb38ca36a41b28c9cf184743fac85","placeholder":"​","style":"IPY_MODEL_d434c6f3f81b435a96d6c3915219a489","value":" 624/624 [00:00&lt;00:00, 6.82kB/s]"}},"b951503897da4285a9f4ffdf3171a7f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"97697dc1702344528767d200bb154355":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b853cc8dfb134c14b101fd357ef88c5d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1e7d36c5a9a442dd90deb45127106fc3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b0df16a743174f559e1c872565109191":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3fadb38ca36a41b28c9cf184743fac85":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d434c6f3f81b435a96d6c3915219a489":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6W1aW9ScsEKd","executionInfo":{"status":"ok","timestamp":1650209284275,"user_tz":240,"elapsed":103014,"user":{"displayName":"Zhong Zheng","userId":"00802841473920121231"}},"outputId":"58bc79c0-d465-499f-dcc8-50406b08471e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import sys\n","\n","# TODO: change this to the path to your homework folder\n","# GOOGLE_DRIVE_PATH_AFTER_MYDRIVE = 'NLP /Final project/ChineseHumorSentiment-master/data'\n","# GOOGLE_DRIVE_PATH = os.path.join('drive', 'Shared drives', GOOGLE_DRIVE_PATH_AFTER_MYDRIVE)\n","# print(os.listdir(GOOGLE_DRIVE_PATH))\n","# sys.path.append(GOOGLE_DRIVE_PATH)"],"metadata":{"id":"IGcW4IjHsQ7E","executionInfo":{"status":"ok","timestamp":1650209297156,"user_tz":240,"elapsed":178,"user":{"displayName":"Zhong Zheng","userId":"00802841473920121231"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"uB4JJk4msXVG","executionInfo":{"status":"ok","timestamp":1650209297900,"user_tz":240,"elapsed":522,"user":{"displayName":"Zhong Zheng","userId":"00802841473920121231"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["task1_set = pd.read_csv(\"drive/Shared drives/NLP Final Project/human_label/Human_Label_balanced_test_task1.csv - Copy of balanced_test_task1.csv\",encoding='utf8')\n","task2_set = pd.read_csv(\"drive/Shared drives/NLP Final Project/human_label/Human_Label_balanced_test_task2.csv - Copy of balanced_test_task2.csv\",encoding='utf8')\n","task1_set = task1_set.drop(columns=['id', 'Unnamed: 0'])\n","task2_set = task2_set.drop(columns=['id', 'Unnamed: 0'])"],"metadata":{"id":"X518fmy5sZFr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PBYfHTEusbg-","executionInfo":{"status":"ok","timestamp":1650056644682,"user_tz":240,"elapsed":6295,"user":{"displayName":"Lawrence Zheng","userId":"00235738317953399170"}},"outputId":"ac16afc7-1af3-4bdb-bcd6-58e2af5ef273"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cpu\n"]}]},{"cell_type":"markdown","source":["# Human Label accuracy"],"metadata":{"id":"r1_DK_Se0ip4"}},{"cell_type":"code","source":["import numpy as np\n","gold_label_1 = np.array(task1_set[\"label\"])\n","gold_label_2 = np.array(task2_set[\"label\"])\n","human_label_1 = np.array(task1_set[\"label_human\"])\n","human_label_2 = np.array(task2_set[\"Label_human\"])"],"metadata":{"id":"AJEHsVTn0hsz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["human_label_1[human_label_1 == 9] = 0"],"metadata":{"id":"h0dPsAMdAyS_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(type(gold_label_1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9uSIdf8x0hnw","executionInfo":{"status":"ok","timestamp":1650056644684,"user_tz":240,"elapsed":6,"user":{"displayName":"Lawrence Zheng","userId":"00235738317953399170"}},"outputId":"4c0b77c4-9cca-4114-d06b-20893c69cd69"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'numpy.ndarray'>\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import f1_score"],"metadata":{"id":"mej0GWvBAm8c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["human_label_2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wbQf0wGWBcDe","executionInfo":{"status":"ok","timestamp":1650056645370,"user_tz":240,"elapsed":4,"user":{"displayName":"Lawrence Zheng","userId":"00235738317953399170"}},"outputId":"bd8672bb-d943-4fb4-f77e-4434f5f259d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([ 2.,  2.,  2.,  2.,  2.,  2.,  0.,  1.,  2.,  2.,  2.,  1.,  1.,\n","        1.,  1.,  2.,  1.,  2.,  2.,  2.,  1.,  2.,  1.,  2.,  1.,  0.,\n","        1.,  0.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  2.,  0.,  2.,  1.,\n","        1.,  2.,  2.,  2.,  2.,  0.,  1.,  1.,  1.,  0.,  2.,  1.,  0.,\n","        0.,  1.,  0.,  2.,  0.,  2.,  2.,  2.,  1.,  2.,  2.,  0.,  0.,\n","        1.,  2.,  1.,  2.,  2.,  2.,  1.,  1.,  2.,  1.,  0.,  2.,  2.,\n","        2.,  2.,  2.,  1.,  2.,  2.,  2.,  1.,  0.,  1.,  1.,  0.,  1.,\n","        1.,  2.,  1.,  1.,  2.,  2.,  1.,  0.,  1.,  2.,  2.,  2.,  2.,\n","        1.,  2.,  0.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  0.,\n","        1.,  0.,  0.,  1.,  1.,  2.,  1.,  1.,  2.,  1.,  1.,  2.,  2.,\n","        2.,  2.,  1.,  2.,  2.,  0.,  0.,  2.,  1.,  1.,  2.,  1.,  2.,\n","        2.,  1.,  1.,  2.,  2.,  0.,  1.,  1.,  1.,  1.,  1.,  2.,  2.,\n","        0.,  0.,  2.,  2.,  2.,  2.,  1.,  1.,  1.,  0.,  2.,  1.,  1.,\n","        2.,  2.,  1.,  2.,  0.,  0.,  2.,  2.,  1.,  1.,  1.,  2.,  2.,\n","        1.,  2.,  1.,  0.,  2.,  1.,  2.,  0.,  1.,  2.,  1.,  1.,  2.,\n","        2.,  2.,  2.,  1.,  2.,  1.,  1.,  2.,  1.,  2.,  2.,  2.,  1.,\n","        2.,  2.,  1.,  2.,  2.,  0.,  2.,  2.,  2.,  1.,  1.,  1.,  2.,\n","        1.,  1.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  0.,  2.,  2.,\n","        1.,  2.,  2.,  2.,  2.,  2.,  1.,  2.,  2.,  2.,  2.,  0.,  1.,\n","        0.,  1.,  0.,  1.,  2.,  2.,  1.,  0.,  1.,  2.,  2.,  2.,  2.,\n","        2.,  2.,  2.,  2.,  1.,  1.,  1.,  2.,  2.,  1.,  2.,  2.,  2.,\n","        1.,  1.,  2.,  2.,  2.,  2.,  1.,  1., nan,  2.,  2.,  1.,  2.,\n","        1.,  2., nan,  1.,  0.,  1.,  1.,  2.,  1.,  2.,  2.,  2.,  2.,\n","        1.,  2.,  2.,  2.,  1.,  0.,  1.,  1.,  2.,  0.,  0.,  1.,  0.,\n","        0.,  1.,  1.,  1.,  2.,  1.,  1.,  2.,  0.,  1.,  2.,  1.,  2.,\n","        2.,  2.,  0.,  1.,  1.,  1.,  2.,  0.,  0.,  2.,  2.,  1.,  1.,\n","        2.,  1.,  1.,  1.,  2.,  2.,  2.,  0.,  0.,  1.,  1.,  1.,  2.,\n","        1.,  1.,  1.,  2.,  1.,  0.,  0.,  2.,  2.,  2.,  0.,  2.,  0.,\n","        1.,  1.,  0.,  1.,  0.,  1.,  0.,  1.,  1.,  1.,  0.,  2.,  2.,\n","        0.,  2.,  2.,  0.,  1.,  1.,  2.,  0.,  0.,  0.,  1.,  1.,  2.,\n","        1.,  1.,  0.,  0.,  1.,  1.,  1.,  1.,  0.,  1.,  2.,  2.,  1.,\n","        2.,  2.,  2.,  2.,  0.,  2.,  2.,  1.,  0.,  1.,  1.,  1.,  0.,\n","        1.,  2.,  2.,  1.,  0.,  2.,  2.,  1.,  1.,  1.,  1.,  0.,  2.,\n","        1.,  2.,  1.,  1.,  1.,  2.,  2.,  1.,  1.,  2.,  2.,  0.,  2.,\n","        0.,  0.,  2.,  0.,  2.,  2.,  2.,  2.,  0., nan,  0.,  1.,  2.,\n","        0.,  2.,  2.,  2.,  1.,  1.,  2.,  0.,  1.,  1.,  2.,  2.,  2.,\n","        1.,  0.,  2.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  1.,  2.,  1.,\n","        2.,  0.,  0.,  0.,  0.,  2.,  1.,  0.,  2.,  0.,  1.,  0.,  2.,\n","        2.,  1.,  1.,  2.,  2.,  2.,  0.,  1.,  1.,  1.,  0.,  0.,  1.,\n","        0.,  0.,  0.,  0.,  2.,  1.,  0.,  1.,  1.,  1.,  1.,  1.,  2.,\n","        2.,  1.,  0.,  2.,  2.,  2.,  0.,  1., nan,  0.,  2.,  1.,  0.,\n","        2.,  2.,  1.,  0.,  1.,  1.,  2.,  1.,  0.,  1.,  1.,  0.,  1.,\n","        0.,  1.,  1.,  1.,  0.,  1.,  2.,  2.,  2.,  0.,  1.,  0.,  0.,\n","        0.,  2.,  0.,  1.,  2.,  1.,  1.,  0.,  0.,  0.,  1.,  1.,  2.,\n","        1.,  2.,  1.,  2.,  2.,  2.,  0.,  1.,  2.,  2.,  2.,  1.,  2.,\n","        1.,  2.,  2.,  0.,  2.,  1.,  1.,  2.,  2.,  1.,  1.,  2.,  1.,\n","        2.])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["f1_score(gold_label_2, human_label_2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":317},"id":"WmZ8oeGkAqza","executionInfo":{"status":"error","timestamp":1650056337825,"user_tz":240,"elapsed":265,"user":{"displayName":"Lawrence Zheng","userId":"00235738317953399170"}},"outputId":"9d829ef2-1a5d-4ce7-d7c6-72be0aaff7a5"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-94b2a45c2d5b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgold_label_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhuman_label_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m     )\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1268\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f-score\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1270\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1271\u001b[0m     )\n\u001b[1;32m   1272\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1346\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"average has to be one of \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m     \u001b[0;31m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m     \u001b[0;31m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36mtype_of_target\u001b[0;34m(y)\u001b[0m\n\u001b[1;32m    322\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"f\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m         \u001b[0;31m# [.1, .2, 3] or [[.1, .2, 3]] or [[1., .2]] and not [1., 2., 3.]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"continuous\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    114\u001b[0m             raise ValueError(\n\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[0;32m--> 116\u001b[0;31m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                 )\n\u001b[1;32m    118\u001b[0m             )\n","\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."]}]},{"cell_type":"code","source":["correct_num = 0\n","for index, value in gold_label_1.items():\n","  if human_label_1[index] == value:\n","    correct_num += 1\n","\n","print(correct_num/len(gold_label_1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8y3KjHg10hbO","executionInfo":{"status":"ok","timestamp":1648930649110,"user_tz":240,"elapsed":110,"user":{"displayName":"Star Zhong","userId":"03050321856587794365"}},"outputId":"8af83e8f-6c2d-469b-e732-cd903ca1b741"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7983333333333333\n"]}]},{"cell_type":"code","source":["correct_num_2 = 0\n","for index, value in gold_label_2.items():\n","  if human_label_2[index] == value:\n","    correct_num_2 += 1\n","\n","print(correct_num_2/len(gold_label_2))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yS4H0IsV7Rb4","executionInfo":{"status":"ok","timestamp":1648930678219,"user_tz":240,"elapsed":5,"user":{"displayName":"Star Zhong","userId":"03050321856587794365"}},"outputId":"67f485c9-eaa4-4cfd-c105-48d54862a066"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.3739565943238731\n"]}]},{"cell_type":"markdown","source":["# Humor feature analysis"],"metadata":{"id":"33KDsMX6Iu5L"}},{"cell_type":"code","source":["train_set = pd.read_csv(\"drive/Shared drives/NLP Final Project/Dataset/balanced_train_task2.csv\",encoding='utf8')\n","# task2_set = pd.read_csv(\"drive/Shared drives/NLP Final Project/human_label/Human_Label_balanced_test_task2.csv - Copy of balanced_test_task2.csv\",encoding='utf8')\n","train_set = train_set.drop(columns=['id', 'Unnamed: 0'])\n","# task2_set = task2_set.drop(columns=['id', 'Unnamed: 0'])"],"metadata":{"id":"4eBVRTl3I751","executionInfo":{"status":"ok","timestamp":1650209305245,"user_tz":240,"elapsed":1869,"user":{"displayName":"Zhong Zheng","userId":"00802841473920121231"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["zero_num_wife = (train_set[\"joke\"][train_set[\"label\"] == 0]).apply(lambda s: any(x in s for x in [\"不\", \"没\",\"无\",\"非\",\"莫\",\"弗\",\"勿\",\"毋\",\"未\",\"否\",\"别\",\"無\",\"休\",\"难道\"])).sum()\n","one_num_wife = (train_set[\"joke\"][train_set[\"label\"] == 1]).apply(lambda s: any(x in s for x in [\"不\", \"没\",\"无\",\"非\",\"莫\",\"弗\",\"勿\",\"毋\",\"未\",\"否\",\"别\",\"無\",\"休\",\"难道\"])).sum()\n","two_num_wife = (train_set[\"joke\"][train_set[\"label\"] == 2]).apply(lambda s: any(x in s for x in[\"不\", \"没\",\"无\",\"非\",\"莫\",\"弗\",\"勿\",\"毋\",\"未\",\"否\",\"别\",\"無\",\"休\",\"难道\"])).sum()\n","\n","print(\"0:\", zero_num_wife, \"1:\", one_num_wife, \"2:\", two_num_wife)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uiv7lM3SIzPj","executionInfo":{"status":"ok","timestamp":1650209307004,"user_tz":240,"elapsed":174,"user":{"displayName":"Zhong Zheng","userId":"00802841473920121231"}},"outputId":"945f19f7-8c2a-4b4f-a7b5-e407aa3019da"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["0: 2447 1: 2065 2: 2336\n"]}]},{"cell_type":"code","source":["reference_name1 = (train_set[\"joke\"][train_set[\"label\"] == 0]).apply(lambda s: any(x in s for x in ['爸','妈','婆','公' ,'学生','老师', '医生','律师','家长','阿凡提'])).sum()\n","reference_name2 = (train_set[\"joke\"][train_set[\"label\"] == 1]).apply(lambda s: any(x in s for x in['爸','妈','婆','公' ,'学生','老师', '医生','律师','家长','阿凡提'])).sum()\n","reference_name3 = (train_set[\"joke\"][train_set[\"label\"] == 2]).apply(lambda s: any(x in s for x in['爸','妈','婆','公' ,'学生','老师', '医生','律师','家长','阿凡提'])).sum()\n","\n","print(\"0:\", reference_name1, \"1:\", reference_name2, \"2:\", reference_name3)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"irRRpog2P6re","executionInfo":{"status":"ok","timestamp":1650209488119,"user_tz":240,"elapsed":211,"user":{"displayName":"Zhong Zheng","userId":"00802841473920121231"}},"outputId":"52c21d09-1a2c-468b-c4d1-a8997f65d25b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["0: 1285 1: 1068 2: 1390\n"]}]},{"cell_type":"markdown","source":["1. ： 冒号 0: 2600 1: 1898 2: 2578\n","2. 、 顿号 0: 213 1: 99 2: 135\n","3. ['爸','妈','婆','公' ,'学生','老师', '医生','律师','家长','阿凡提']，0: 1285 1: 1068 2: 1390\n","4. 感叹号，！， 0: 1356 1: 1069 2: 1458\n","5. 问号，？，0: 1650 1: 1328 2: 1700\n"],"metadata":{"id":"QcISn8yIJOYV"}},{"cell_type":"code","source":["train_set_1 = pd.read_csv(\"drive/Shared drives/NLP Final Project/Dataset/balanced_train_task1.csv\",encoding='utf8')"],"metadata":{"id":"079almboPKaQ","executionInfo":{"status":"ok","timestamp":1650209311160,"user_tz":240,"elapsed":540,"user":{"displayName":"Zhong Zheng","userId":"00802841473920121231"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["zero_num_wife = (train_set_1[\"joke\"][train_set_1[\"label\"] == 0]).apply(lambda s: any(x in s for x in [\"不\", \"没\",\"无\",\"非\",\"莫\",\"弗\",\"勿\",\"毋\",\"未\",\"否\",\"别\",\"無\",\"休\",\"难道\"])).sum()\n","one_num_wife = (train_set_1[\"joke\"][train_set_1[\"label\"] == 1]).apply(lambda s: any(x in s for x in [\"不\", \"没\",\"无\",\"非\",\"莫\",\"弗\",\"勿\",\"毋\",\"未\",\"否\",\"别\",\"無\",\"休\",\"难道\"])).sum()\n","# two_num_wife = (train_set_1[\"joke\"][train_set_1[\"label\"] == 2]).apply(lambda s: any(x in s for x in[\"不\", \"没\",\"无\",\"非\",\"莫\",\"弗\",\"勿\",\"毋\",\"未\",\"否\",\"别\",\"無\",\"休\",\"难道\"])).sum()\n","\n","print(\"0:\", zero_num_wife, \"1:\", one_num_wife)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dNK8NXckPO3s","executionInfo":{"status":"ok","timestamp":1648935917453,"user_tz":240,"elapsed":170,"user":{"displayName":"Star Zhong","userId":"03050321856587794365"}},"outputId":"c107fdeb-28ff-4c58-e987-37cbc36b07d1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0: 1699 1: 2200\n"]}]},{"cell_type":"code","source":["reference_name1 = (train_set_1[\"joke\"][train_set_1[\"label\"] == 0]).apply(lambda s: any(x in s for x in[\"、\"])).sum()\n","reference_name2 = (train_set_1[\"joke\"][train_set_1[\"label\"] == 1]).apply(lambda s: any(x in s for x in[\"、\"])).sum()\n","# reference_name3 = (train_set_1[\"joke\"][train_set_1[\"label\"] == 2]).apply(lambda s: any(x in s for x in[\"、\"])).sum()\n","\n","print(\"0:\", reference_name1, \"1:\", reference_name2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rte_TjGMRnyU","executionInfo":{"status":"ok","timestamp":1650209344197,"user_tz":240,"elapsed":146,"user":{"displayName":"Zhong Zheng","userId":"00802841473920121231"}},"outputId":"709e04e8-96e9-4d22-accc-6a9fd92d4209"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["0: 0 1: 60\n"]}]},{"cell_type":"markdown","source":["task 1 feature:\n","1. ： 冒号 0: 290 1: 1809\n","2. 、 顿号 0: 0 1: 60\n","3. ['爸','妈','婆','公' ,'学生','老师', '医生','律师','家长','阿凡提']，0: 158 1: 965\n","4. 感叹号，！， 0: 214 1: 950\n","5. 问号，？，0: 529 1: 1247\n"],"metadata":{"id":"WViZm_9SSLMY"}},{"cell_type":"markdown","source":["## Preprocessing"],"metadata":{"id":"s9SbTv08snyf"}},{"cell_type":"code","source":["! pip install transformers"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYJTXUsFsmp1","executionInfo":{"status":"ok","timestamp":1648863592186,"user_tz":240,"elapsed":9591,"user":{"displayName":"Lawrence Zheng","userId":"00235738317953399170"}},"outputId":"e63f1faa-78a1-4db5-8c27-877314fbdf11"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n","\u001b[K     |████████████████████████████████| 3.8 MB 7.1 MB/s \n","\u001b[?25hCollecting sacremoses\n","  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n","\u001b[K     |████████████████████████████████| 895 kB 44.3 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n","Collecting tokenizers!=0.11.3,>=0.11.1\n","  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n","\u001b[K     |████████████████████████████████| 6.5 MB 41.8 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n","\u001b[K     |████████████████████████████████| 67 kB 5.8 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 32.6 MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.17.0\n"]}]},{"cell_type":"code","source":["train_set"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"rTHE_qHRtpLi","executionInfo":{"status":"ok","timestamp":1648863592187,"user_tz":240,"elapsed":12,"user":{"displayName":"Lawrence Zheng","userId":"00235738317953399170"}},"outputId":"ded4ce18-3bb6-4acf-fc9b-0cb81c2b81e4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                   joke  label\n","0     请告诉我，史密斯先生，面试官问道，您还有什么其他您认为值得一提的技能吗？ 的确还有，应聘者谦...      1\n","1     一辆小汽车急速闯过红灯，刚好被警察拦住。 喂，你难道没有看见红灯吗？ 不，真对不起，我看到红...      1\n","2     教官子与县丞子厮打，教官子屡负，归而哭诉其母。母 曰：彼家终日吃肉，故恁般强健会打。你家终日...      0\n","3                                   经验是我们秃顶后大自然赋予我们的梳子。      1\n","4                         正在进行中 - 它可能很慢，但它很稳定。请耐心等待。谢谢。      1\n","...                                                 ...    ...\n","8995  一官员因贪污受贿被判刑，儿子探监时，说自己大学毕业找不到工作。 官员说：会有人来帮你的，我在...      1\n","8996  某医院急诊室送来一位病人，医生见病人痛得厉害，就给他服了一片止痛药，可是病人仍疼痛不止。 家...      2\n","8997  小学时候，每天出发前爸爸总会躺在床上提醒我： 校徽，红领巾，书包......天天被他说烦了，...      2\n","8998  法官问犯人：“你一点法律意识没有怎么不去学点法律知识啊？” 犯人答：“你当我傻啊！知法犯法―...      2\n","8999  一天，迂公拜访袁洗马（官名，分管图书典籍），看见他手里拿着一本书边看边走，便问是什么书。洗马...      0\n","\n","[9000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-98b05bcd-ee88-4925-909e-85350ced9fba\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>joke</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>请告诉我，史密斯先生，面试官问道，您还有什么其他您认为值得一提的技能吗？ 的确还有，应聘者谦...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>一辆小汽车急速闯过红灯，刚好被警察拦住。 喂，你难道没有看见红灯吗？ 不，真对不起，我看到红...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>教官子与县丞子厮打，教官子屡负，归而哭诉其母。母 曰：彼家终日吃肉，故恁般强健会打。你家终日...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>经验是我们秃顶后大自然赋予我们的梳子。</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>正在进行中 - 它可能很慢，但它很稳定。请耐心等待。谢谢。</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8995</th>\n","      <td>一官员因贪污受贿被判刑，儿子探监时，说自己大学毕业找不到工作。 官员说：会有人来帮你的，我在...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8996</th>\n","      <td>某医院急诊室送来一位病人，医生见病人痛得厉害，就给他服了一片止痛药，可是病人仍疼痛不止。 家...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8997</th>\n","      <td>小学时候，每天出发前爸爸总会躺在床上提醒我： 校徽，红领巾，书包......天天被他说烦了，...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8998</th>\n","      <td>法官问犯人：“你一点法律意识没有怎么不去学点法律知识啊？” 犯人答：“你当我傻啊！知法犯法―...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>8999</th>\n","      <td>一天，迂公拜访袁洗马（官名，分管图书典籍），看见他手里拿着一本书边看边走，便问是什么书。洗马...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>9000 rows × 2 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98b05bcd-ee88-4925-909e-85350ced9fba')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-98b05bcd-ee88-4925-909e-85350ced9fba button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-98b05bcd-ee88-4925-909e-85350ced9fba');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n","\n","example_text = train_set.iloc[900, 0]\n","bert_input = tokenizer(example_text,padding='max_length', max_length = 150, \n","                       truncation=True, return_tensors=\"pt\")"],"metadata":{"id":"fh4m2nT6sgvq","executionInfo":{"status":"ok","timestamp":1648863595021,"user_tz":240,"elapsed":2843,"user":{"displayName":"Lawrence Zheng","userId":"00235738317953399170"}},"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["d058ac43cc0e4f568acfab6d6840ec73","d6d766a297f14c22b4bd11478abc4f73","f5c407298af24c37a3bfe8c013e7fd00","04740890d1a74a0aa4a08618abdfcbb0","730f3da0565645deab733a07d2586734","64d51e29603443d8a8c022729b0e8999","7cf385ddf184432d8753b3ece9cbb377","eb36be46ca4c4f979676a2719b8b1071","d92e7177e96c489eb77e5bf3ea0679fb","46a9b80bf1ab4c3a92606088b3fdd090","e10cdbba720440bda681cc237b5008cb","6a22b8906f194753a7c727a6bddc62aa","06d3d0b51cdc4501b84dff909fbd2e97","a275f10b895a4ebaad36df1d194d337e","a9696fe46f3642a5af8e760cb49b9ce7","3a9188b4afc84427bbd1a821e403ad2c","f6f3916ac59b42e78236004ea60ca999","cd549a4e49cd47f39baadd50aeee76b1","34b96e7e7f67440987b9dfc8d9a013fc","c5cec62e3a494d2cbc61b5d7ac10ceea","e50fea7844e746c683bcb76391c668f4","c43288e4cf364c89bf5391e62f149ca6","d2a03c2a83a94d499c08123809d010ae","b874273c33d24ad589214edf0e88f5a3","381c42b53ba84b87949157fb706f30c1","a712ecb04b8549b8a7128053db6a1187","b951503897da4285a9f4ffdf3171a7f9","97697dc1702344528767d200bb154355","b853cc8dfb134c14b101fd357ef88c5d","1e7d36c5a9a442dd90deb45127106fc3","b0df16a743174f559e1c872565109191","3fadb38ca36a41b28c9cf184743fac85","d434c6f3f81b435a96d6c3915219a489"]},"outputId":"e6cac9b1-69a2-4d93-e227-4439e694ba46"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/107k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d058ac43cc0e4f568acfab6d6840ec73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6a22b8906f194753a7c727a6bddc62aa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/624 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2a03c2a83a94d499c08123809d010ae"}},"metadata":{}}]},{"cell_type":"code","source":["print(bert_input['input_ids'])\n","print(bert_input['token_type_ids'])\n","print(bert_input['attention_mask'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-JS-2Ekqs7Vw","executionInfo":{"status":"ok","timestamp":1648863595179,"user_tz":240,"elapsed":5,"user":{"displayName":"Lawrence Zheng","userId":"00235738317953399170"}},"outputId":"90ef395b-9c7a-4cb0-ee88-4d137f34fca6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[ 101, 7370,  749,  689,  865, 1736,  672, 1912, 8024, 3680,  702,  782,\n","         6963,  833, 3119, 5815,  800, 3064, 4905, 4638,  691, 6205,  511,  102,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0]])\n","tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0]])\n","tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0]])\n"]}]},{"cell_type":"code","source":["example_text = tokenizer.decode(bert_input.input_ids[0])\n","\n","print(example_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_a1vmoO6tIcZ","executionInfo":{"status":"ok","timestamp":1648863599211,"user_tz":240,"elapsed":4035,"user":{"displayName":"Lawrence Zheng","userId":"00235738317953399170"}},"outputId":"b58c7064-26d9-4f23-979f-b34711824856"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[CLS] 除 了 业 余 园 丁 外 ， 每 个 人 都 会 收 获 他 播 种 的 东 西 。 [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"]}]},{"cell_type":"code","source":["import torch\n","import numpy as np\n","from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-chinese')\n","labels = {'true': 1,\n","          'false': 0\n","          }\n","\n","class Dataset(torch.utils.data.Dataset):\n","\n","    def __init__(self, df):\n","\n","        self.labels = [label for label in df['label']]\n","        self.texts = [tokenizer(text, \n","                               padding='max_length', max_length = 150, truncation=True,\n","                                return_tensors=\"pt\") for text in df['joke']]\n","\n","    def classes(self):\n","        return self.labels\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def get_batch_labels(self, idx):\n","        # Fetch a batch of labels\n","        return np.array(self.labels[idx])\n","\n","    def get_batch_texts(self, idx):\n","        # Fetch a batch of inputs\n","        return self.texts[idx]\n","\n","    def __getitem__(self, idx):\n","\n","        batch_texts = self.get_batch_texts(idx)\n","        batch_y = self.get_batch_labels(idx)\n","\n","        return batch_texts, batch_y"],"metadata":{"id":"2wSN-WNStZYY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import nn\n","from transformers import BertModel\n","\n","class BertClassifier(nn.Module):\n","\n","    def __init__(self, dropout=0.5):\n","\n","        super(BertClassifier, self).__init__()\n","\n","        self.bert = BertModel.from_pretrained('bert-base-chinese')\n","        # self.dropout = nn.Dropout(dropout)\n","        self.rnn = nn.LSTM(768, 200, num_layers = 3, device='cuda', batch_first=False, bidirectional=True)\n","        self.linear = nn.Linear(400, 3)\n","        self.softmax = nn.Softmax(dim=1)\n","\n","    def forward(self, input_id, mask):\n","\n","        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n","        # dropout_output = self.dropout(pooled_output)\n","        rnn_output, _ = self.rnn(pooled_output.view(len(pooled_output), 1, -1))\n","        linear_output = self.linear(rnn_output)\n","        final_layer = (linear_output).reshape((2, 3))\n","        return final_layer"],"metadata":{"id":"s8See-kHuVAz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.optim import Adam\n","from tqdm import tqdm\n","\n","def train(model, train_data, val_data, learning_rate, epochs):\n","\n","    train, val = Dataset(train_data), Dataset(val_data)\n","\n","    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n","    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n","\n","    use_cuda = torch.cuda.is_available()\n","    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n","\n","    if use_cuda:\n","\n","            model = model.cuda()\n","            criterion = criterion.cuda()\n","\n","    for epoch_num in range(epochs):\n","\n","            total_acc_train = 0\n","            total_loss_train = 0\n","\n","            for train_input, train_label in tqdm(train_dataloader):\n","\n","                train_label = train_label.to(device)\n","                mask = train_input['attention_mask'].to(device)\n","                input_id = train_input['input_ids'].squeeze(1).to(device)\n","\n","                output = model(input_id, mask)\n","                \n","                batch_loss = criterion(output, train_label)\n","                total_loss_train += batch_loss.item()\n","                acc = (output.argmax(dim=1) == train_label).sum().item()\n","                total_acc_train += acc\n","\n","                model.zero_grad()\n","                batch_loss.backward()\n","                optimizer.step()\n","            \n","            total_acc_val = 0\n","            total_loss_val = 0\n","\n","            with torch.no_grad():\n","\n","                for val_input, val_label in val_dataloader:\n","\n","                    val_label = val_label.to(device)\n","                    mask = val_input['attention_mask'].to(device)\n","                    input_id = val_input['input_ids'].squeeze(1).to(device)\n","\n","                    output = model(input_id, mask)\n","\n","                    batch_loss = criterion(output, val_label)\n","                    total_loss_val += batch_loss.item()\n","                    \n","                    acc = (output.argmax(dim=1) == val_label).sum().item()\n","                    total_acc_val += acc\n","            \n","            print(\n","                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} \\\n","                | Train Accuracy: {total_acc_train / len(train_data): .3f} \\\n","                | Val Loss: {total_loss_val / len(val_data): .3f} \\\n","                | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n","                  \n","EPOCHS = 10\n","model = BertClassifier()\n","LR = 1e-6\n","              \n","train(model, train_set, test_set, LR, EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KtFacpczu_75","outputId":"1a9c9330-1e43-4a4d-89d5-fdc5de5eea12","executionInfo":{"status":"ok","timestamp":1648870115831,"user_tz":240,"elapsed":3279083,"user":{"displayName":"Lawrence Zheng","userId":"00235738317953399170"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","100%|██████████| 4500/4500 [05:31<00:00, 13.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 1 | Train Loss:  0.548                 | Train Accuracy:  0.345                 | Val Loss:  0.546                 | Val Accuracy:  0.423\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4500/4500 [05:10<00:00, 14.51it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 2 | Train Loss:  0.543                 | Train Accuracy:  0.471                 | Val Loss:  0.538                 | Val Accuracy:  0.487\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4500/4500 [05:11<00:00, 14.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 3 | Train Loss:  0.532                 | Train Accuracy:  0.503                 | Val Loss:  0.528                 | Val Accuracy:  0.471\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4500/4500 [05:09<00:00, 14.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 4 | Train Loss:  0.517                 | Train Accuracy:  0.506                 | Val Loss:  0.514                 | Val Accuracy:  0.485\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4500/4500 [05:09<00:00, 14.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 5 | Train Loss:  0.502                 | Train Accuracy:  0.516                 | Val Loss:  0.500                 | Val Accuracy:  0.506\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4500/4500 [05:11<00:00, 14.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 6 | Train Loss:  0.489                 | Train Accuracy:  0.525                 | Val Loss:  0.492                 | Val Accuracy:  0.508\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4500/4500 [05:09<00:00, 14.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 7 | Train Loss:  0.476                 | Train Accuracy:  0.541                 | Val Loss:  0.491                 | Val Accuracy:  0.512\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4500/4500 [05:09<00:00, 14.56it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 8 | Train Loss:  0.465                 | Train Accuracy:  0.566                 | Val Loss:  0.491                 | Val Accuracy:  0.516\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4500/4500 [05:09<00:00, 14.52it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 9 | Train Loss:  0.447                 | Train Accuracy:  0.595                 | Val Loss:  0.493                 | Val Accuracy:  0.524\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 4500/4500 [05:08<00:00, 14.58it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epochs: 10 | Train Loss:  0.429                 | Train Accuracy:  0.622                 | Val Loss:  0.496                 | Val Accuracy:  0.524\n"]}]},{"cell_type":"code","source":["torch.save(model, \"drive/Shared drives/NLP Final Project/Star_model/three_way_bert\")"],"metadata":{"id":"oVH_JxwzvelN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"m_fNUkb1U04F"},"execution_count":null,"outputs":[]}]}